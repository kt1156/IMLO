{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "euC_NH-FqAGv"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau\n",
    "\n",
    "# Define transformations\n",
    "data_transform_train = transforms.Compose([\n",
    "    #transforms.Resize((256, 256)),\n",
    "    #transforms.CenterCrop((224, 224)),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "data_transform_test = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "training_data = datasets.Flowers102(\n",
    "    root=\"data\",\n",
    "    split=\"train\",\n",
    "    download=True,\n",
    "    transform=data_transform_train\n",
    ")\n",
    "\n",
    "test_data = datasets.Flowers102(\n",
    "    root=\"data\",\n",
    "    split=\"test\",\n",
    "    download=True,\n",
    "    transform=data_transform_test\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l1vRj_jegnS5",
    "outputId": "f5ab57e3-ea14-4d66-b2f6-b179ecbd0e88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# Get cpu, gpu or mps device for training.\n",
    "\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "zM6jbzVqgrnq"
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, 1, padding=3)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1, padding=3)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, 1, padding=3)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.conv4 = nn.Conv2d(128, 256, 3, 1, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(256)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(57600, 1024)\n",
    "        self.bn5 = nn.BatchNorm1d(1024)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.bn6 = nn.BatchNorm1d(512)\n",
    "        self.fc3 = nn.Linear(512, 256)\n",
    "        self.bn7 = nn.BatchNorm1d(256)\n",
    "        self.fc4 = nn.Linear(256, 102)\n",
    "        self.logsoftmax = nn.LogSoftmax(dim=1)\n",
    "        self.dropout = nn.Dropout(p=0.5)  # Add dropout layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.bn4(self.conv4(x)))\n",
    "        x = self.pool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.bn5(self.fc1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.bn6(self.fc2(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.bn7(self.fc3(x)))\n",
    "        x = self.fc4(x)\n",
    "        return self.logsoftmax(x)\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "\n",
    "learning_rate = 1e-3\n",
    "batch_size = 64\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Dusq5PqTgthA"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min',factor=0.5, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "t_zHA_p8gvuZ"
   },
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    " \n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)  # move data to device\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 1 == 0:\n",
    "            loss, current = loss.item(), batch * batch_size + len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    " \n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)  # move data to device\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "h80qYfVWq71M",
    "outputId": "ade84eb8-d00f-449c-95e5-60490fb28d22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\keela\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\Conv_v8.cpp:919.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 4.670414  [   64/ 1020]\n",
      "loss: 4.714071  [  128/ 1020]\n",
      "loss: 4.678077  [  192/ 1020]\n",
      "loss: 4.741866  [  256/ 1020]\n",
      "loss: 4.679268  [  320/ 1020]\n",
      "loss: 4.630064  [  384/ 1020]\n",
      "loss: 4.691455  [  448/ 1020]\n",
      "loss: 4.535616  [  512/ 1020]\n",
      "loss: 4.526471  [  576/ 1020]\n",
      "loss: 4.607384  [  640/ 1020]\n",
      "loss: 4.632476  [  704/ 1020]\n",
      "loss: 4.692322  [  768/ 1020]\n",
      "loss: 4.513004  [  832/ 1020]\n",
      "loss: 4.433926  [  896/ 1020]\n",
      "loss: 4.421004  [  960/ 1020]\n",
      "loss: 4.382081  [ 1020/ 1020]\n",
      "Test Error: \n",
      " Accuracy: 4.9%, Avg loss: 4.425043 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 4.403438  [   64/ 1020]\n",
      "loss: 4.214503  [  128/ 1020]\n",
      "loss: 4.287131  [  192/ 1020]\n",
      "loss: 4.277182  [  256/ 1020]\n",
      "loss: 4.193135  [  320/ 1020]\n",
      "loss: 4.239917  [  384/ 1020]\n",
      "loss: 4.127452  [  448/ 1020]\n",
      "loss: 4.148071  [  512/ 1020]\n",
      "loss: 4.224117  [  576/ 1020]\n",
      "loss: 4.164958  [  640/ 1020]\n",
      "loss: 4.075252  [  704/ 1020]\n",
      "loss: 4.124741  [  768/ 1020]\n",
      "loss: 4.255957  [  832/ 1020]\n",
      "loss: 4.066466  [  896/ 1020]\n",
      "loss: 4.086101  [  960/ 1020]\n",
      "loss: 4.058970  [ 1020/ 1020]\n",
      "Test Error: \n",
      " Accuracy: 6.5%, Avg loss: 4.122206 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 3.965374  [   64/ 1020]\n",
      "loss: 3.960639  [  128/ 1020]\n",
      "loss: 3.828439  [  192/ 1020]\n",
      "loss: 3.880853  [  256/ 1020]\n",
      "loss: 3.981369  [  320/ 1020]\n",
      "loss: 3.930948  [  384/ 1020]\n",
      "loss: 3.748302  [  448/ 1020]\n",
      "loss: 3.823781  [  512/ 1020]\n",
      "loss: 3.971098  [  576/ 1020]\n",
      "loss: 3.849539  [  640/ 1020]\n",
      "loss: 3.890375  [  704/ 1020]\n",
      "loss: 3.683722  [  768/ 1020]\n",
      "loss: 3.824600  [  832/ 1020]\n",
      "loss: 3.972942  [  896/ 1020]\n",
      "loss: 3.769266  [  960/ 1020]\n",
      "loss: 3.789516  [ 1020/ 1020]\n",
      "Test Error: \n",
      " Accuracy: 8.1%, Avg loss: 3.976255 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 3.665773  [   64/ 1020]\n",
      "loss: 3.602070  [  128/ 1020]\n",
      "loss: 3.646894  [  192/ 1020]\n",
      "loss: 3.671174  [  256/ 1020]\n",
      "loss: 3.645935  [  320/ 1020]\n",
      "loss: 3.559320  [  384/ 1020]\n",
      "loss: 3.594953  [  448/ 1020]\n",
      "loss: 3.722600  [  512/ 1020]\n",
      "loss: 3.680912  [  576/ 1020]\n",
      "loss: 3.628789  [  640/ 1020]\n",
      "loss: 3.633787  [  704/ 1020]\n",
      "loss: 3.717988  [  768/ 1020]\n",
      "loss: 3.603621  [  832/ 1020]\n",
      "loss: 3.469514  [  896/ 1020]\n",
      "loss: 3.387534  [  960/ 1020]\n",
      "loss: 3.478908  [ 1020/ 1020]\n",
      "Test Error: \n",
      " Accuracy: 14.1%, Avg loss: 3.683603 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 3.480468  [   64/ 1020]\n",
      "loss: 3.417547  [  128/ 1020]\n",
      "loss: 3.204525  [  192/ 1020]\n",
      "loss: 3.428592  [  256/ 1020]\n",
      "loss: 3.421874  [  320/ 1020]\n",
      "loss: 3.393026  [  384/ 1020]\n",
      "loss: 3.358853  [  448/ 1020]\n",
      "loss: 3.501098  [  512/ 1020]\n",
      "loss: 3.286376  [  576/ 1020]\n",
      "loss: 3.299645  [  640/ 1020]\n",
      "loss: 3.297178  [  704/ 1020]\n",
      "loss: 3.579280  [  768/ 1020]\n",
      "loss: 3.449247  [  832/ 1020]\n",
      "loss: 3.361972  [  896/ 1020]\n",
      "loss: 3.303132  [  960/ 1020]\n",
      "loss: 3.358475  [ 1020/ 1020]\n",
      "Test Error: \n",
      " Accuracy: 13.2%, Avg loss: 3.591278 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 3.304778  [   64/ 1020]\n",
      "loss: 3.319412  [  128/ 1020]\n",
      "loss: 2.952306  [  192/ 1020]\n",
      "loss: 3.074353  [  256/ 1020]\n",
      "loss: 3.332223  [  320/ 1020]\n",
      "loss: 2.971909  [  384/ 1020]\n",
      "loss: 2.939376  [  448/ 1020]\n",
      "loss: 3.279316  [  512/ 1020]\n",
      "loss: 3.213166  [  576/ 1020]\n",
      "loss: 3.414229  [  640/ 1020]\n",
      "loss: 3.009470  [  704/ 1020]\n",
      "loss: 2.992735  [  768/ 1020]\n",
      "loss: 3.026780  [  832/ 1020]\n",
      "loss: 3.303890  [  896/ 1020]\n",
      "loss: 3.004459  [  960/ 1020]\n",
      "loss: 3.113876  [ 1020/ 1020]\n",
      "Test Error: \n",
      " Accuracy: 17.3%, Avg loss: 3.377558 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 2.855598  [   64/ 1020]\n",
      "loss: 2.881777  [  128/ 1020]\n",
      "loss: 2.917758  [  192/ 1020]\n",
      "loss: 2.809454  [  256/ 1020]\n",
      "loss: 3.020494  [  320/ 1020]\n",
      "loss: 3.036434  [  384/ 1020]\n",
      "loss: 3.206592  [  448/ 1020]\n",
      "loss: 2.978398  [  512/ 1020]\n",
      "loss: 2.927141  [  576/ 1020]\n",
      "loss: 3.003003  [  640/ 1020]\n",
      "loss: 2.743432  [  704/ 1020]\n",
      "loss: 3.010045  [  768/ 1020]\n",
      "loss: 3.012854  [  832/ 1020]\n",
      "loss: 2.807035  [  896/ 1020]\n",
      "loss: 2.803375  [  960/ 1020]\n",
      "loss: 3.009436  [ 1020/ 1020]\n",
      "Test Error: \n",
      " Accuracy: 20.1%, Avg loss: 3.327446 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 2.781283  [   64/ 1020]\n",
      "loss: 2.882248  [  128/ 1020]\n",
      "loss: 2.712245  [  192/ 1020]\n",
      "loss: 2.798870  [  256/ 1020]\n",
      "loss: 2.980088  [  320/ 1020]\n",
      "loss: 2.671064  [  384/ 1020]\n",
      "loss: 2.788714  [  448/ 1020]\n",
      "loss: 2.680216  [  512/ 1020]\n",
      "loss: 2.633043  [  576/ 1020]\n",
      "loss: 2.583992  [  640/ 1020]\n",
      "loss: 2.592384  [  704/ 1020]\n",
      "loss: 2.659844  [  768/ 1020]\n",
      "loss: 2.794713  [  832/ 1020]\n",
      "loss: 2.638029  [  896/ 1020]\n",
      "loss: 2.805724  [  960/ 1020]\n",
      "loss: 2.787120  [ 1020/ 1020]\n",
      "Test Error: \n",
      " Accuracy: 22.1%, Avg loss: 3.195034 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 2.778239  [   64/ 1020]\n",
      "loss: 2.478302  [  128/ 1020]\n",
      "loss: 2.487577  [  192/ 1020]\n",
      "loss: 2.772941  [  256/ 1020]\n",
      "loss: 2.434296  [  320/ 1020]\n",
      "loss: 2.473871  [  384/ 1020]\n",
      "loss: 2.643897  [  448/ 1020]\n",
      "loss: 2.511708  [  512/ 1020]\n",
      "loss: 2.612476  [  576/ 1020]\n",
      "loss: 2.409438  [  640/ 1020]\n",
      "loss: 2.721850  [  704/ 1020]\n",
      "loss: 2.529204  [  768/ 1020]\n",
      "loss: 2.633882  [  832/ 1020]\n",
      "loss: 2.442543  [  896/ 1020]\n",
      "loss: 2.350653  [  960/ 1020]\n",
      "loss: 2.755208  [ 1020/ 1020]\n",
      "Test Error: \n",
      " Accuracy: 21.8%, Avg loss: 3.113029 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 2.408195  [   64/ 1020]\n",
      "loss: 2.308993  [  128/ 1020]\n",
      "loss: 2.385549  [  192/ 1020]\n",
      "loss: 2.422001  [  256/ 1020]\n",
      "loss: 2.368371  [  320/ 1020]\n",
      "loss: 2.216964  [  384/ 1020]\n",
      "loss: 2.307607  [  448/ 1020]\n",
      "loss: 2.337636  [  512/ 1020]\n",
      "loss: 2.528450  [  576/ 1020]\n",
      "loss: 2.278847  [  640/ 1020]\n",
      "loss: 2.456758  [  704/ 1020]\n",
      "loss: 2.471415  [  768/ 1020]\n",
      "loss: 2.351622  [  832/ 1020]\n",
      "loss: 2.478230  [  896/ 1020]\n",
      "loss: 2.553791  [  960/ 1020]\n",
      "loss: 2.288942  [ 1020/ 1020]\n",
      "Test Error: \n",
      " Accuracy: 25.3%, Avg loss: 3.014459 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 2.176143  [   64/ 1020]\n",
      "loss: 2.133166  [  128/ 1020]\n",
      "loss: 2.333814  [  192/ 1020]\n",
      "loss: 2.196215  [  256/ 1020]\n",
      "loss: 2.051252  [  320/ 1020]\n",
      "loss: 2.217022  [  384/ 1020]\n",
      "loss: 2.254019  [  448/ 1020]\n",
      "loss: 1.916864  [  512/ 1020]\n",
      "loss: 2.193911  [  576/ 1020]\n",
      "loss: 2.465875  [  640/ 1020]\n",
      "loss: 2.336114  [  704/ 1020]\n",
      "loss: 2.233115  [  768/ 1020]\n",
      "loss: 2.165954  [  832/ 1020]\n",
      "loss: 2.324255  [  896/ 1020]\n",
      "loss: 2.307624  [  960/ 1020]\n",
      "loss: 2.263314  [ 1020/ 1020]\n",
      "Test Error: \n",
      " Accuracy: 24.5%, Avg loss: 3.111705 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 1.881196  [   64/ 1020]\n",
      "loss: 1.832746  [  128/ 1020]\n",
      "loss: 2.169029  [  192/ 1020]\n",
      "loss: 2.007439  [  256/ 1020]\n",
      "loss: 1.942923  [  320/ 1020]\n",
      "loss: 2.048258  [  384/ 1020]\n",
      "loss: 2.323008  [  448/ 1020]\n",
      "loss: 2.243214  [  512/ 1020]\n",
      "loss: 2.064340  [  576/ 1020]\n",
      "loss: 2.209386  [  640/ 1020]\n",
      "loss: 1.928266  [  704/ 1020]\n",
      "loss: 2.028839  [  768/ 1020]\n",
      "loss: 2.457709  [  832/ 1020]\n",
      "loss: 2.257058  [  896/ 1020]\n",
      "loss: 2.020541  [  960/ 1020]\n",
      "loss: 2.133197  [ 1020/ 1020]\n",
      "Test Error: \n",
      " Accuracy: 26.5%, Avg loss: 3.014295 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 2.000395  [   64/ 1020]\n",
      "loss: 1.855879  [  128/ 1020]\n",
      "loss: 1.819344  [  192/ 1020]\n",
      "loss: 1.798528  [  256/ 1020]\n",
      "loss: 1.956212  [  320/ 1020]\n",
      "loss: 1.997322  [  384/ 1020]\n",
      "loss: 1.922918  [  448/ 1020]\n",
      "loss: 1.872010  [  512/ 1020]\n",
      "loss: 1.872074  [  576/ 1020]\n",
      "loss: 1.980902  [  640/ 1020]\n",
      "loss: 2.225645  [  704/ 1020]\n",
      "loss: 1.854691  [  768/ 1020]\n",
      "loss: 1.801167  [  832/ 1020]\n",
      "loss: 2.074759  [  896/ 1020]\n",
      "loss: 2.243061  [  960/ 1020]\n",
      "loss: 1.994372  [ 1020/ 1020]\n",
      "Test Error: \n",
      " Accuracy: 27.4%, Avg loss: 2.954949 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 1.655949  [   64/ 1020]\n",
      "loss: 1.860062  [  128/ 1020]\n",
      "loss: 1.888524  [  192/ 1020]\n",
      "loss: 1.909632  [  256/ 1020]\n",
      "loss: 1.748864  [  320/ 1020]\n",
      "loss: 1.891650  [  384/ 1020]\n",
      "loss: 1.874558  [  448/ 1020]\n",
      "loss: 1.547696  [  512/ 1020]\n",
      "loss: 1.979219  [  576/ 1020]\n",
      "loss: 1.586612  [  640/ 1020]\n",
      "loss: 1.916514  [  704/ 1020]\n",
      "loss: 1.899228  [  768/ 1020]\n",
      "loss: 1.627116  [  832/ 1020]\n",
      "loss: 1.784921  [  896/ 1020]\n",
      "loss: 1.800569  [  960/ 1020]\n",
      "loss: 1.824407  [ 1020/ 1020]\n",
      "Test Error: \n",
      " Accuracy: 30.1%, Avg loss: 2.835248 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 1.520551  [   64/ 1020]\n",
      "loss: 1.846848  [  128/ 1020]\n",
      "loss: 1.600229  [  192/ 1020]\n",
      "loss: 1.768802  [  256/ 1020]\n",
      "loss: 1.607461  [  320/ 1020]\n",
      "loss: 1.556816  [  384/ 1020]\n",
      "loss: 1.625923  [  448/ 1020]\n",
      "loss: 1.533038  [  512/ 1020]\n",
      "loss: 1.649988  [  576/ 1020]\n",
      "loss: 1.502158  [  640/ 1020]\n",
      "loss: 1.805762  [  704/ 1020]\n",
      "loss: 1.718475  [  768/ 1020]\n",
      "loss: 1.635000  [  832/ 1020]\n",
      "loss: 1.724210  [  896/ 1020]\n",
      "loss: 1.667435  [  960/ 1020]\n",
      "loss: 1.537540  [ 1020/ 1020]\n",
      "Test Error: \n",
      " Accuracy: 29.5%, Avg loss: 2.863566 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 1.534502  [   64/ 1020]\n",
      "loss: 1.514686  [  128/ 1020]\n",
      "loss: 1.304172  [  192/ 1020]\n",
      "loss: 1.566499  [  256/ 1020]\n",
      "loss: 1.713202  [  320/ 1020]\n",
      "loss: 1.757922  [  384/ 1020]\n",
      "loss: 1.388330  [  448/ 1020]\n",
      "loss: 1.554020  [  512/ 1020]\n",
      "loss: 1.488703  [  576/ 1020]\n",
      "loss: 1.513676  [  640/ 1020]\n",
      "loss: 1.583485  [  704/ 1020]\n",
      "loss: 1.464368  [  768/ 1020]\n",
      "loss: 1.547061  [  832/ 1020]\n",
      "loss: 1.495252  [  896/ 1020]\n",
      "loss: 1.590983  [  960/ 1020]\n",
      "loss: 1.614868  [ 1020/ 1020]\n",
      "Test Error: \n",
      " Accuracy: 31.8%, Avg loss: 2.730629 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 1.445375  [   64/ 1020]\n",
      "loss: 1.295687  [  128/ 1020]\n",
      "loss: 1.279212  [  192/ 1020]\n",
      "loss: 1.306280  [  256/ 1020]\n",
      "loss: 1.238755  [  320/ 1020]\n",
      "loss: 1.185146  [  384/ 1020]\n",
      "loss: 1.490355  [  448/ 1020]\n",
      "loss: 1.577560  [  512/ 1020]\n",
      "loss: 1.230263  [  576/ 1020]\n",
      "loss: 1.533393  [  640/ 1020]\n",
      "loss: 1.532473  [  704/ 1020]\n",
      "loss: 1.744935  [  768/ 1020]\n",
      "loss: 1.500908  [  832/ 1020]\n",
      "loss: 1.444688  [  896/ 1020]\n",
      "loss: 1.421592  [  960/ 1020]\n",
      "loss: 1.421183  [ 1020/ 1020]\n",
      "Test Error: \n",
      " Accuracy: 33.7%, Avg loss: 2.687975 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 1.149327  [   64/ 1020]\n",
      "loss: 1.257208  [  128/ 1020]\n",
      "loss: 1.109390  [  192/ 1020]\n",
      "loss: 1.184805  [  256/ 1020]\n",
      "loss: 1.351807  [  320/ 1020]\n",
      "loss: 1.280969  [  384/ 1020]\n",
      "loss: 1.018414  [  448/ 1020]\n",
      "loss: 1.221368  [  512/ 1020]\n",
      "loss: 1.440974  [  576/ 1020]\n",
      "loss: 1.435075  [  640/ 1020]\n",
      "loss: 1.310822  [  704/ 1020]\n",
      "loss: 1.285398  [  768/ 1020]\n",
      "loss: 1.307603  [  832/ 1020]\n",
      "loss: 1.390970  [  896/ 1020]\n",
      "loss: 1.290370  [  960/ 1020]\n",
      "loss: 1.300485  [ 1020/ 1020]\n",
      "Test Error: \n",
      " Accuracy: 32.3%, Avg loss: 2.763668 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 1.289195  [   64/ 1020]\n",
      "loss: 1.064419  [  128/ 1020]\n",
      "loss: 1.129508  [  192/ 1020]\n",
      "loss: 1.257319  [  256/ 1020]\n",
      "loss: 1.113455  [  320/ 1020]\n",
      "loss: 1.182146  [  384/ 1020]\n",
      "loss: 1.108097  [  448/ 1020]\n",
      "loss: 1.058688  [  512/ 1020]\n",
      "loss: 1.219321  [  576/ 1020]\n",
      "loss: 1.139663  [  640/ 1020]\n",
      "loss: 1.277192  [  704/ 1020]\n",
      "loss: 1.277287  [  768/ 1020]\n",
      "loss: 1.352624  [  832/ 1020]\n",
      "loss: 1.034218  [  896/ 1020]\n",
      "loss: 1.156486  [  960/ 1020]\n",
      "loss: 0.898411  [ 1020/ 1020]\n",
      "Test Error: \n",
      " Accuracy: 34.4%, Avg loss: 2.654926 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.997559  [   64/ 1020]\n",
      "loss: 1.074399  [  128/ 1020]\n",
      "loss: 0.877824  [  192/ 1020]\n",
      "loss: 1.053973  [  256/ 1020]\n",
      "loss: 0.997140  [  320/ 1020]\n",
      "loss: 1.077069  [  384/ 1020]\n",
      "loss: 1.109310  [  448/ 1020]\n",
      "loss: 1.123670  [  512/ 1020]\n",
      "loss: 1.151162  [  576/ 1020]\n",
      "loss: 1.587329  [  640/ 1020]\n",
      "loss: 1.062339  [  704/ 1020]\n",
      "loss: 1.172236  [  768/ 1020]\n",
      "loss: 0.959032  [  832/ 1020]\n",
      "loss: 1.057392  [  896/ 1020]\n",
      "loss: 0.985552  [  960/ 1020]\n",
      "loss: 1.293713  [ 1020/ 1020]\n",
      "Test Error: \n",
      " Accuracy: 36.3%, Avg loss: 2.634031 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.892459  [   64/ 1020]\n",
      "loss: 0.862059  [  128/ 1020]\n",
      "loss: 0.961212  [  192/ 1020]\n",
      "loss: 0.803966  [  256/ 1020]\n",
      "loss: 1.017655  [  320/ 1020]\n",
      "loss: 0.873804  [  384/ 1020]\n",
      "loss: 0.981044  [  448/ 1020]\n",
      "loss: 1.137458  [  512/ 1020]\n",
      "loss: 1.037411  [  576/ 1020]\n",
      "loss: 1.056341  [  640/ 1020]\n",
      "loss: 0.924428  [  704/ 1020]\n",
      "loss: 1.159818  [  768/ 1020]\n",
      "loss: 1.175264  [  832/ 1020]\n",
      "loss: 0.994547  [  896/ 1020]\n",
      "loss: 1.170643  [  960/ 1020]\n",
      "loss: 1.286806  [ 1020/ 1020]\n",
      "Test Error: \n",
      " Accuracy: 30.2%, Avg loss: 2.974361 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.877229  [   64/ 1020]\n",
      "loss: 1.015849  [  128/ 1020]\n",
      "loss: 0.945180  [  192/ 1020]\n",
      "loss: 0.860029  [  256/ 1020]\n",
      "loss: 0.942888  [  320/ 1020]\n",
      "loss: 0.988423  [  384/ 1020]\n",
      "loss: 1.030506  [  448/ 1020]\n",
      "loss: 0.964438  [  512/ 1020]\n",
      "loss: 0.984685  [  576/ 1020]\n",
      "loss: 1.077683  [  640/ 1020]\n",
      "loss: 0.984013  [  704/ 1020]\n",
      "loss: 1.078530  [  768/ 1020]\n",
      "loss: 1.152934  [  832/ 1020]\n",
      "loss: 1.035444  [  896/ 1020]\n",
      "loss: 1.004482  [  960/ 1020]\n",
      "loss: 1.162662  [ 1020/ 1020]\n",
      "Test Error: \n",
      " Accuracy: 36.0%, Avg loss: 2.656861 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.698937  [   64/ 1020]\n",
      "loss: 0.798846  [  128/ 1020]\n",
      "loss: 1.063458  [  192/ 1020]\n",
      "loss: 0.782159  [  256/ 1020]\n",
      "loss: 0.893633  [  320/ 1020]\n",
      "loss: 0.689220  [  384/ 1020]\n",
      "loss: 0.824612  [  448/ 1020]\n",
      "loss: 0.917906  [  512/ 1020]\n",
      "loss: 0.760406  [  576/ 1020]\n",
      "loss: 0.720084  [  640/ 1020]\n",
      "loss: 0.749430  [  704/ 1020]\n",
      "loss: 0.750788  [  768/ 1020]\n",
      "loss: 0.953023  [  832/ 1020]\n",
      "loss: 0.648250  [  896/ 1020]\n",
      "loss: 0.732142  [  960/ 1020]\n",
      "loss: 0.772915  [ 1020/ 1020]\n",
      "Test Error: \n",
      " Accuracy: 37.5%, Avg loss: 2.582063 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.678032  [   64/ 1020]\n",
      "loss: 0.696865  [  128/ 1020]\n",
      "loss: 0.614883  [  192/ 1020]\n",
      "loss: 0.710918  [  256/ 1020]\n",
      "loss: 0.742841  [  320/ 1020]\n",
      "loss: 0.686579  [  384/ 1020]\n",
      "loss: 0.613296  [  448/ 1020]\n",
      "loss: 0.922618  [  512/ 1020]\n",
      "loss: 0.744482  [  576/ 1020]\n",
      "loss: 0.764341  [  640/ 1020]\n",
      "loss: 0.789928  [  704/ 1020]\n",
      "loss: 0.804270  [  768/ 1020]\n",
      "loss: 0.849645  [  832/ 1020]\n",
      "loss: 0.693759  [  896/ 1020]\n",
      "loss: 0.936799  [  960/ 1020]\n",
      "loss: 0.812914  [ 1020/ 1020]\n",
      "Test Error: \n",
      " Accuracy: 35.4%, Avg loss: 2.660814 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.703256  [   64/ 1020]\n",
      "loss: 0.655764  [  128/ 1020]\n",
      "loss: 0.551024  [  192/ 1020]\n",
      "loss: 0.757424  [  256/ 1020]\n",
      "loss: 0.681715  [  320/ 1020]\n",
      "loss: 0.793972  [  384/ 1020]\n",
      "loss: 0.682017  [  448/ 1020]\n",
      "loss: 0.680321  [  512/ 1020]\n",
      "loss: 0.604812  [  576/ 1020]\n",
      "loss: 0.702723  [  640/ 1020]\n",
      "loss: 0.655393  [  704/ 1020]\n",
      "loss: 0.666325  [  768/ 1020]\n",
      "loss: 0.862304  [  832/ 1020]\n",
      "loss: 0.616892  [  896/ 1020]\n",
      "loss: 0.686300  [  960/ 1020]\n",
      "loss: 0.643615  [ 1020/ 1020]\n",
      "Test Error: \n",
      " Accuracy: 37.8%, Avg loss: 2.609062 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.641886  [   64/ 1020]\n",
      "loss: 0.561812  [  128/ 1020]\n",
      "loss: 0.597873  [  192/ 1020]\n",
      "loss: 0.580010  [  256/ 1020]\n",
      "loss: 0.633976  [  320/ 1020]\n",
      "loss: 0.654057  [  384/ 1020]\n",
      "loss: 0.739233  [  448/ 1020]\n",
      "loss: 0.553967  [  512/ 1020]\n",
      "loss: 0.549662  [  576/ 1020]\n",
      "loss: 0.685561  [  640/ 1020]\n",
      "loss: 0.483884  [  704/ 1020]\n",
      "loss: 0.488392  [  768/ 1020]\n",
      "loss: 0.695600  [  832/ 1020]\n",
      "loss: 0.760042  [  896/ 1020]\n",
      "loss: 0.599614  [  960/ 1020]\n",
      "loss: 0.540420  [ 1020/ 1020]\n",
      "Test Error: \n",
      " Accuracy: 37.6%, Avg loss: 2.658573 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.593439  [   64/ 1020]\n",
      "loss: 0.538972  [  128/ 1020]\n",
      "loss: 0.377937  [  192/ 1020]\n",
      "loss: 0.490979  [  256/ 1020]\n",
      "loss: 0.587952  [  320/ 1020]\n",
      "loss: 0.510709  [  384/ 1020]\n",
      "loss: 0.517215  [  448/ 1020]\n",
      "loss: 0.543275  [  512/ 1020]\n",
      "loss: 0.524808  [  576/ 1020]\n",
      "loss: 0.460356  [  640/ 1020]\n",
      "loss: 0.490222  [  704/ 1020]\n",
      "loss: 0.472872  [  768/ 1020]\n",
      "loss: 0.638794  [  832/ 1020]\n",
      "loss: 0.493547  [  896/ 1020]\n",
      "loss: 0.611664  [  960/ 1020]\n",
      "loss: 0.540648  [ 1020/ 1020]\n",
      "Test Error: \n",
      " Accuracy: 34.3%, Avg loss: 2.746367 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.484719  [   64/ 1020]\n",
      "loss: 0.318700  [  128/ 1020]\n",
      "loss: 0.530999  [  192/ 1020]\n",
      "loss: 0.554451  [  256/ 1020]\n",
      "loss: 0.563480  [  320/ 1020]\n",
      "loss: 0.564380  [  384/ 1020]\n",
      "loss: 0.525768  [  448/ 1020]\n",
      "loss: 0.436486  [  512/ 1020]\n",
      "loss: 0.557938  [  576/ 1020]\n",
      "loss: 0.392160  [  640/ 1020]\n",
      "loss: 0.542548  [  704/ 1020]\n",
      "loss: 0.467651  [  768/ 1020]\n",
      "loss: 0.425280  [  832/ 1020]\n",
      "loss: 0.517686  [  896/ 1020]\n",
      "loss: 0.408758  [  960/ 1020]\n",
      "loss: 0.663426  [ 1020/ 1020]\n",
      "Test Error: \n",
      " Accuracy: 36.6%, Avg loss: 2.737908 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.493811  [   64/ 1020]\n",
      "loss: 0.288707  [  128/ 1020]\n",
      "loss: 0.407982  [  192/ 1020]\n",
      "loss: 0.461638  [  256/ 1020]\n",
      "loss: 0.422536  [  320/ 1020]\n",
      "loss: 0.374927  [  384/ 1020]\n",
      "loss: 0.478485  [  448/ 1020]\n",
      "loss: 0.636226  [  512/ 1020]\n",
      "loss: 0.583503  [  576/ 1020]\n",
      "loss: 0.353205  [  640/ 1020]\n",
      "loss: 0.391038  [  704/ 1020]\n",
      "loss: 0.458499  [  768/ 1020]\n",
      "loss: 0.600898  [  832/ 1020]\n",
      "loss: 0.543124  [  896/ 1020]\n",
      "loss: 0.423633  [  960/ 1020]\n",
      "loss: 0.642079  [ 1020/ 1020]\n",
      "Test Error: \n",
      " Accuracy: 36.3%, Avg loss: 2.781392 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.482097  [   64/ 1020]\n",
      "loss: 0.446721  [  128/ 1020]\n",
      "loss: 0.405929  [  192/ 1020]\n",
      "loss: 0.385845  [  256/ 1020]\n",
      "loss: 0.532146  [  320/ 1020]\n",
      "loss: 0.352536  [  384/ 1020]\n",
      "loss: 0.473377  [  448/ 1020]\n",
      "loss: 0.374760  [  512/ 1020]\n",
      "loss: 0.340777  [  576/ 1020]\n",
      "loss: 0.473329  [  640/ 1020]\n",
      "loss: 0.370433  [  704/ 1020]\n",
      "loss: 0.526417  [  768/ 1020]\n",
      "loss: 0.301778  [  832/ 1020]\n",
      "loss: 0.490453  [  896/ 1020]\n",
      "loss: 0.333208  [  960/ 1020]\n",
      "loss: 0.408434  [ 1020/ 1020]\n",
      "Test Error: \n",
      " Accuracy: 37.5%, Avg loss: 2.668892 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.262276  [   64/ 1020]\n",
      "loss: 0.343565  [  128/ 1020]\n",
      "loss: 0.428535  [  192/ 1020]\n",
      "loss: 0.378362  [  256/ 1020]\n",
      "loss: 0.502430  [  320/ 1020]\n",
      "loss: 0.326534  [  384/ 1020]\n",
      "loss: 0.381560  [  448/ 1020]\n",
      "loss: 0.338154  [  512/ 1020]\n",
      "loss: 0.382495  [  576/ 1020]\n",
      "loss: 0.371044  [  640/ 1020]\n",
      "loss: 0.309127  [  704/ 1020]\n",
      "loss: 0.395930  [  768/ 1020]\n",
      "loss: 0.309607  [  832/ 1020]\n",
      "loss: 0.359083  [  896/ 1020]\n",
      "loss: 0.311910  [  960/ 1020]\n",
      "loss: 0.292697  [ 1020/ 1020]\n",
      "Test Error: \n",
      " Accuracy: 38.4%, Avg loss: 2.635935 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.236734  [   64/ 1020]\n",
      "loss: 0.288903  [  128/ 1020]\n",
      "loss: 0.433427  [  192/ 1020]\n",
      "loss: 0.251645  [  256/ 1020]\n",
      "loss: 0.285166  [  320/ 1020]\n",
      "loss: 0.230554  [  384/ 1020]\n",
      "loss: 0.218393  [  448/ 1020]\n",
      "loss: 0.317599  [  512/ 1020]\n",
      "loss: 0.298443  [  576/ 1020]\n",
      "loss: 0.286297  [  640/ 1020]\n",
      "loss: 0.248146  [  704/ 1020]\n",
      "loss: 0.265819  [  768/ 1020]\n",
      "loss: 0.366413  [  832/ 1020]\n",
      "loss: 0.272580  [  896/ 1020]\n",
      "loss: 0.308200  [  960/ 1020]\n",
      "loss: 0.242335  [ 1020/ 1020]\n",
      "Test Error: \n",
      " Accuracy: 40.3%, Avg loss: 2.592833 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.335497  [   64/ 1020]\n",
      "loss: 0.259365  [  128/ 1020]\n",
      "loss: 0.269987  [  192/ 1020]\n",
      "loss: 0.248162  [  256/ 1020]\n",
      "loss: 0.325537  [  320/ 1020]\n",
      "loss: 0.340359  [  384/ 1020]\n",
      "loss: 0.250339  [  448/ 1020]\n",
      "loss: 0.246707  [  512/ 1020]\n",
      "loss: 0.223122  [  576/ 1020]\n",
      "loss: 0.282273  [  640/ 1020]\n",
      "loss: 0.207528  [  704/ 1020]\n",
      "loss: 0.334376  [  768/ 1020]\n",
      "loss: 0.244870  [  832/ 1020]\n",
      "loss: 0.262934  [  896/ 1020]\n",
      "loss: 0.241556  [  960/ 1020]\n",
      "loss: 0.305142  [ 1020/ 1020]\n",
      "Test Error: \n",
      " Accuracy: 40.1%, Avg loss: 2.608444 \n",
      "\n",
      "Early stopping triggered.\n",
      "Done! This took 30.45 minutes\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define early stopping parameters\n",
    "patience = 10\n",
    "min_delta = 0.001\n",
    "\n",
    "best_loss = float('inf')\n",
    "counter = 0\n",
    "\n",
    "# Timer\n",
    "start_time = time.time()\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    validation_loss = test_loop(test_dataloader, model, loss_fn)\n",
    "    scheduler.step(validation_loss)\n",
    "\n",
    "    # Early stopping logic\n",
    "    if validation_loss < best_loss - min_delta:\n",
    "        best_loss = validation_loss\n",
    "        counter = 0\n",
    "    else:\n",
    "        counter += 1\n",
    "        if counter >= patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "            \n",
    "end_time = round((time.time()-start_time)/60, 3)\n",
    "\n",
    "print(\"Done! This took\", end_time, \"minutes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V28",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
