{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "euC_NH-FqAGv"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau\n",
    "\n",
    "# Define transformations\n",
    "data_transform_train = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.CenterCrop((224, 224)),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "data_transform_test = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "training_data = datasets.Flowers102(\n",
    "    root=\"data\",\n",
    "    split=\"train\",\n",
    "    download=True,\n",
    "    transform=data_transform_train\n",
    ")\n",
    "\n",
    "test_data = datasets.Flowers102(\n",
    "    root=\"data\",\n",
    "    split=\"test\",\n",
    "    download=True,\n",
    "    transform=data_transform_test\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l1vRj_jegnS5",
    "outputId": "f5ab57e3-ea14-4d66-b2f6-b179ecbd0e88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# Get cpu, gpu or mps device for training.\n",
    "\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "zM6jbzVqgrnq"
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, 1, padding=2)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1, padding=2)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, 1, padding=2)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.conv4 = nn.Conv2d(128, 256, 3, 1, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(256)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(50176, 1024)\n",
    "        self.bn5 = nn.BatchNorm1d(1024)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.bn6 = nn.BatchNorm1d(512)\n",
    "        self.fc3 = nn.Linear(512, 256)\n",
    "        self.bn7 = nn.BatchNorm1d(256)\n",
    "        self.fc4 = nn.Linear(256, 102)\n",
    "        self.logsoftmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n",
    "        x = self.pool(F.relu(self.bn4(self.conv4(x))))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.bn5(self.fc1(x)))\n",
    "        #x = self.dropout(x)\n",
    "        x = F.relu(self.bn6(self.fc2(x)))\n",
    "        #x = self.dropout(x)\n",
    "        x = F.relu(self.bn7(self.fc3(x)))\n",
    "        x = self.fc4(x)\n",
    "        return self.logsoftmax(x)\n",
    "\n",
    "model = NeuralNetwork()\n",
    "\n",
    "learning_rate = 1e-3\n",
    "batch_size = 64\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Dusq5PqTgthA"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "#scheduler= StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min',factor=0.1, patience=5, threshold=0.0001, threshold_mode='abs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "t_zHA_p8gvuZ"
   },
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    " \n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 1 == 0:\n",
    "            loss, current = loss.item(), batch * batch_size + len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    " \n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "h80qYfVWq71M",
    "outputId": "ade84eb8-d00f-449c-95e5-60490fb28d22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 4.666916  [   64/ 1020]\n",
      "loss: 4.582284  [  128/ 1020]\n",
      "loss: 4.563449  [  192/ 1020]\n",
      "loss: 4.528890  [  256/ 1020]\n",
      "loss: 4.605833  [  320/ 1020]\n",
      "loss: 4.359064  [  384/ 1020]\n",
      "loss: 4.551963  [  448/ 1020]\n",
      "loss: 4.166698  [  512/ 1020]\n",
      "loss: 4.283953  [  576/ 1020]\n",
      "loss: 4.370963  [  640/ 1020]\n",
      "loss: 4.297260  [  704/ 1020]\n",
      "loss: 4.229011  [  768/ 1020]\n",
      "loss: 4.320312  [  832/ 1020]\n",
      "loss: 4.174986  [  896/ 1020]\n",
      "loss: 4.007374  [  960/ 1020]\n",
      "loss: 4.045008  [ 1020/ 1020]\n",
      "Test Error: \n",
      " Accuracy: 3.6%, Avg loss: 4.378238 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 3.713843  [   64/ 1020]\n",
      "loss: 3.684795  [  128/ 1020]\n",
      "loss: 3.738848  [  192/ 1020]\n",
      "loss: 3.754280  [  256/ 1020]\n",
      "loss: 3.747654  [  320/ 1020]\n",
      "loss: 3.613235  [  384/ 1020]\n",
      "loss: 3.613104  [  448/ 1020]\n",
      "loss: 3.439302  [  512/ 1020]\n",
      "loss: 3.465830  [  576/ 1020]\n",
      "loss: 3.469820  [  640/ 1020]\n",
      "loss: 3.470604  [  704/ 1020]\n",
      "loss: 3.556850  [  768/ 1020]\n",
      "loss: 3.687946  [  832/ 1020]\n",
      "loss: 3.636271  [  896/ 1020]\n",
      "loss: 3.539654  [  960/ 1020]\n",
      "loss: 3.242763  [ 1020/ 1020]\n",
      "Test Error: \n",
      " Accuracy: 9.3%, Avg loss: 3.930309 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 3.338122  [   64/ 1020]\n",
      "loss: 3.248192  [  128/ 1020]\n",
      "loss: 3.132566  [  192/ 1020]\n",
      "loss: 3.063712  [  256/ 1020]\n",
      "loss: 3.013791  [  320/ 1020]\n",
      "loss: 3.162829  [  384/ 1020]\n",
      "loss: 3.100710  [  448/ 1020]\n",
      "loss: 3.118368  [  512/ 1020]\n",
      "loss: 3.133280  [  576/ 1020]\n",
      "loss: 3.075523  [  640/ 1020]\n",
      "loss: 3.017644  [  704/ 1020]\n",
      "loss: 3.324412  [  768/ 1020]\n",
      "loss: 3.012197  [  832/ 1020]\n",
      "loss: 3.083468  [  896/ 1020]\n",
      "loss: 3.118986  [  960/ 1020]\n",
      "loss: 3.071385  [ 1020/ 1020]\n",
      "Test Error: \n",
      " Accuracy: 14.8%, Avg loss: 3.547631 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 2.868353  [   64/ 1020]\n",
      "loss: 2.831014  [  128/ 1020]\n",
      "loss: 2.756101  [  192/ 1020]\n",
      "loss: 2.401928  [  256/ 1020]\n",
      "loss: 2.481254  [  320/ 1020]\n",
      "loss: 2.685634  [  384/ 1020]\n",
      "loss: 2.559970  [  448/ 1020]\n",
      "loss: 2.822552  [  512/ 1020]\n",
      "loss: 2.633527  [  576/ 1020]\n",
      "loss: 2.844965  [  640/ 1020]\n",
      "loss: 2.603276  [  704/ 1020]\n",
      "loss: 2.639262  [  768/ 1020]\n",
      "loss: 2.674219  [  832/ 1020]\n",
      "loss: 2.679377  [  896/ 1020]\n",
      "loss: 2.776301  [  960/ 1020]\n",
      "loss: 2.631675  [ 1020/ 1020]\n",
      "Test Error: \n",
      " Accuracy: 19.0%, Avg loss: 3.418477 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 2.267180  [   64/ 1020]\n",
      "loss: 2.347572  [  128/ 1020]\n",
      "loss: 2.389730  [  192/ 1020]\n",
      "loss: 2.285938  [  256/ 1020]\n",
      "loss: 2.292262  [  320/ 1020]\n",
      "loss: 2.425125  [  384/ 1020]\n",
      "loss: 2.281268  [  448/ 1020]\n",
      "loss: 2.498253  [  512/ 1020]\n",
      "loss: 2.280182  [  576/ 1020]\n",
      "loss: 2.280247  [  640/ 1020]\n",
      "loss: 2.346232  [  704/ 1020]\n",
      "loss: 2.309951  [  768/ 1020]\n",
      "loss: 2.281662  [  832/ 1020]\n",
      "loss: 2.340750  [  896/ 1020]\n",
      "loss: 2.445355  [  960/ 1020]\n",
      "loss: 2.272767  [ 1020/ 1020]\n",
      "Test Error: \n",
      " Accuracy: 25.6%, Avg loss: 3.100960 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 2.071815  [   64/ 1020]\n",
      "loss: 2.006934  [  128/ 1020]\n",
      "loss: 2.088609  [  192/ 1020]\n",
      "loss: 1.906497  [  256/ 1020]\n",
      "loss: 1.755656  [  320/ 1020]\n",
      "loss: 1.982348  [  384/ 1020]\n",
      "loss: 1.867832  [  448/ 1020]\n",
      "loss: 2.032639  [  512/ 1020]\n",
      "loss: 1.838149  [  576/ 1020]\n",
      "loss: 1.994832  [  640/ 1020]\n",
      "loss: 1.875572  [  704/ 1020]\n",
      "loss: 1.992809  [  768/ 1020]\n",
      "loss: 2.017869  [  832/ 1020]\n",
      "loss: 1.947550  [  896/ 1020]\n",
      "loss: 1.996930  [  960/ 1020]\n",
      "loss: 2.082010  [ 1020/ 1020]\n",
      "Test Error: \n",
      " Accuracy: 23.8%, Avg loss: 3.120413 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 1.680359  [   64/ 1020]\n",
      "loss: 1.726069  [  128/ 1020]\n",
      "loss: 1.460045  [  192/ 1020]\n",
      "loss: 1.663031  [  256/ 1020]\n",
      "loss: 1.531295  [  320/ 1020]\n",
      "loss: 1.710351  [  384/ 1020]\n",
      "loss: 1.631772  [  448/ 1020]\n",
      "loss: 1.770094  [  512/ 1020]\n",
      "loss: 1.593488  [  576/ 1020]\n",
      "loss: 1.600777  [  640/ 1020]\n",
      "loss: 1.515713  [  704/ 1020]\n",
      "loss: 1.809335  [  768/ 1020]\n",
      "loss: 1.476741  [  832/ 1020]\n",
      "loss: 1.784909  [  896/ 1020]\n",
      "loss: 1.699713  [  960/ 1020]\n",
      "loss: 1.684582  [ 1020/ 1020]\n",
      "Test Error: \n",
      " Accuracy: 27.6%, Avg loss: 2.944689 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 1.366486  [   64/ 1020]\n",
      "loss: 1.385255  [  128/ 1020]\n",
      "loss: 1.104913  [  192/ 1020]\n",
      "loss: 1.175510  [  256/ 1020]\n",
      "loss: 1.447303  [  320/ 1020]\n",
      "loss: 1.428773  [  384/ 1020]\n",
      "loss: 1.249609  [  448/ 1020]\n",
      "loss: 1.249927  [  512/ 1020]\n",
      "loss: 1.299406  [  576/ 1020]\n",
      "loss: 1.461041  [  640/ 1020]\n",
      "loss: 1.235984  [  704/ 1020]\n",
      "loss: 1.428466  [  768/ 1020]\n",
      "loss: 1.293914  [  832/ 1020]\n",
      "loss: 1.362202  [  896/ 1020]\n",
      "loss: 1.338882  [  960/ 1020]\n",
      "loss: 1.328214  [ 1020/ 1020]\n",
      "Test Error: \n",
      " Accuracy: 32.2%, Avg loss: 2.797952 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.941409  [   64/ 1020]\n",
      "loss: 1.057006  [  128/ 1020]\n",
      "loss: 1.012637  [  192/ 1020]\n",
      "loss: 1.040637  [  256/ 1020]\n",
      "loss: 0.952576  [  320/ 1020]\n",
      "loss: 0.977662  [  384/ 1020]\n",
      "loss: 0.880541  [  448/ 1020]\n",
      "loss: 0.924701  [  512/ 1020]\n",
      "loss: 1.033436  [  576/ 1020]\n",
      "loss: 1.127436  [  640/ 1020]\n",
      "loss: 0.990676  [  704/ 1020]\n",
      "loss: 0.934671  [  768/ 1020]\n",
      "loss: 0.980330  [  832/ 1020]\n",
      "loss: 0.945985  [  896/ 1020]\n",
      "loss: 0.835023  [  960/ 1020]\n",
      "loss: 1.062633  [ 1020/ 1020]\n",
      "Test Error: \n",
      " Accuracy: 29.0%, Avg loss: 2.867636 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.793403  [   64/ 1020]\n",
      "loss: 0.730863  [  128/ 1020]\n",
      "loss: 0.723478  [  192/ 1020]\n",
      "loss: 0.755212  [  256/ 1020]\n",
      "loss: 0.710793  [  320/ 1020]\n",
      "loss: 0.780891  [  384/ 1020]\n",
      "loss: 0.745738  [  448/ 1020]\n",
      "loss: 0.921589  [  512/ 1020]\n",
      "loss: 0.728694  [  576/ 1020]\n",
      "loss: 0.759753  [  640/ 1020]\n",
      "loss: 0.801686  [  704/ 1020]\n",
      "loss: 0.854594  [  768/ 1020]\n",
      "loss: 0.636752  [  832/ 1020]\n",
      "loss: 0.772475  [  896/ 1020]\n",
      "loss: 0.765818  [  960/ 1020]\n",
      "loss: 0.830716  [ 1020/ 1020]\n",
      "Test Error: \n",
      " Accuracy: 31.2%, Avg loss: 2.865174 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.611598  [   64/ 1020]\n",
      "loss: 0.537058  [  128/ 1020]\n",
      "loss: 0.790898  [  192/ 1020]\n",
      "loss: 0.490358  [  256/ 1020]\n",
      "loss: 0.591994  [  320/ 1020]\n",
      "loss: 0.705624  [  384/ 1020]\n",
      "loss: 0.463388  [  448/ 1020]\n",
      "loss: 0.455138  [  512/ 1020]\n",
      "loss: 0.597900  [  576/ 1020]\n",
      "loss: 0.535740  [  640/ 1020]\n",
      "loss: 0.600951  [  704/ 1020]\n",
      "loss: 0.609321  [  768/ 1020]\n",
      "loss: 0.615774  [  832/ 1020]\n",
      "loss: 0.654192  [  896/ 1020]\n",
      "loss: 0.594917  [  960/ 1020]\n",
      "loss: 0.599529  [ 1020/ 1020]\n",
      "Test Error: \n",
      " Accuracy: 34.1%, Avg loss: 2.719723 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.510264  [   64/ 1020]\n",
      "loss: 0.435923  [  128/ 1020]\n",
      "loss: 0.312817  [  192/ 1020]\n",
      "loss: 0.394465  [  256/ 1020]\n",
      "loss: 0.457926  [  320/ 1020]\n",
      "loss: 0.435068  [  384/ 1020]\n",
      "loss: 0.368153  [  448/ 1020]\n",
      "loss: 0.462576  [  512/ 1020]\n",
      "loss: 0.409940  [  576/ 1020]\n",
      "loss: 0.446381  [  640/ 1020]\n",
      "loss: 0.336743  [  704/ 1020]\n",
      "loss: 0.438250  [  768/ 1020]\n",
      "loss: 0.453831  [  832/ 1020]\n",
      "loss: 0.476235  [  896/ 1020]\n",
      "loss: 0.390066  [  960/ 1020]\n",
      "loss: 0.384000  [ 1020/ 1020]\n",
      "Test Error: \n",
      " Accuracy: 32.6%, Avg loss: 2.798513 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.255236  [   64/ 1020]\n",
      "loss: 0.264852  [  128/ 1020]\n",
      "loss: 0.356890  [  192/ 1020]\n",
      "loss: 0.301425  [  256/ 1020]\n",
      "loss: 0.321569  [  320/ 1020]\n",
      "loss: 0.247624  [  384/ 1020]\n",
      "loss: 0.362103  [  448/ 1020]\n",
      "loss: 0.307029  [  512/ 1020]\n",
      "loss: 0.362641  [  576/ 1020]\n",
      "loss: 0.350130  [  640/ 1020]\n",
      "loss: 0.329166  [  704/ 1020]\n",
      "loss: 0.286319  [  768/ 1020]\n",
      "loss: 0.371568  [  832/ 1020]\n",
      "loss: 0.238036  [  896/ 1020]\n",
      "loss: 0.259506  [  960/ 1020]\n",
      "loss: 0.236724  [ 1020/ 1020]\n",
      "Test Error: \n",
      " Accuracy: 35.3%, Avg loss: 2.689484 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.202418  [   64/ 1020]\n",
      "loss: 0.204408  [  128/ 1020]\n",
      "loss: 0.242129  [  192/ 1020]\n",
      "loss: 0.237208  [  256/ 1020]\n",
      "loss: 0.213492  [  320/ 1020]\n",
      "loss: 0.234261  [  384/ 1020]\n",
      "loss: 0.266811  [  448/ 1020]\n",
      "loss: 0.208378  [  512/ 1020]\n",
      "loss: 0.233704  [  576/ 1020]\n",
      "loss: 0.250899  [  640/ 1020]\n",
      "loss: 0.202744  [  704/ 1020]\n",
      "loss: 0.217974  [  768/ 1020]\n",
      "loss: 0.351126  [  832/ 1020]\n",
      "loss: 0.247189  [  896/ 1020]\n",
      "loss: 0.240505  [  960/ 1020]\n",
      "loss: 0.228903  [ 1020/ 1020]\n",
      "Test Error: \n",
      " Accuracy: 35.7%, Avg loss: 2.706082 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.182363  [   64/ 1020]\n",
      "loss: 0.171609  [  128/ 1020]\n",
      "loss: 0.148796  [  192/ 1020]\n",
      "loss: 0.183211  [  256/ 1020]\n",
      "loss: 0.221607  [  320/ 1020]\n",
      "loss: 0.116075  [  384/ 1020]\n",
      "loss: 0.153502  [  448/ 1020]\n",
      "loss: 0.124456  [  512/ 1020]\n",
      "loss: 0.155334  [  576/ 1020]\n",
      "loss: 0.185233  [  640/ 1020]\n",
      "loss: 0.165049  [  704/ 1020]\n",
      "loss: 0.193642  [  768/ 1020]\n",
      "loss: 0.243965  [  832/ 1020]\n",
      "loss: 0.212628  [  896/ 1020]\n",
      "loss: 0.141313  [  960/ 1020]\n",
      "loss: 0.150528  [ 1020/ 1020]\n",
      "Test Error: \n",
      " Accuracy: 36.5%, Avg loss: 2.663257 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.118190  [   64/ 1020]\n",
      "loss: 0.104895  [  128/ 1020]\n",
      "loss: 0.122817  [  192/ 1020]\n",
      "loss: 0.143622  [  256/ 1020]\n",
      "loss: 0.118558  [  320/ 1020]\n",
      "loss: 0.203438  [  384/ 1020]\n",
      "loss: 0.136095  [  448/ 1020]\n",
      "loss: 0.124251  [  512/ 1020]\n",
      "loss: 0.147938  [  576/ 1020]\n",
      "loss: 0.196525  [  640/ 1020]\n",
      "loss: 0.114386  [  704/ 1020]\n",
      "loss: 0.126504  [  768/ 1020]\n",
      "loss: 0.122056  [  832/ 1020]\n",
      "loss: 0.164039  [  896/ 1020]\n",
      "loss: 0.189130  [  960/ 1020]\n",
      "loss: 0.189973  [ 1020/ 1020]\n",
      "Test Error: \n",
      " Accuracy: 35.4%, Avg loss: 2.735123 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.120641  [   64/ 1020]\n",
      "loss: 0.151095  [  128/ 1020]\n",
      "loss: 0.079772  [  192/ 1020]\n",
      "loss: 0.126614  [  256/ 1020]\n",
      "loss: 0.094246  [  320/ 1020]\n",
      "loss: 0.157232  [  384/ 1020]\n",
      "loss: 0.091013  [  448/ 1020]\n",
      "loss: 0.113412  [  512/ 1020]\n",
      "loss: 0.123968  [  576/ 1020]\n",
      "loss: 0.085893  [  640/ 1020]\n",
      "loss: 0.119276  [  704/ 1020]\n",
      "loss: 0.106885  [  768/ 1020]\n",
      "loss: 0.132132  [  832/ 1020]\n",
      "loss: 0.086763  [  896/ 1020]\n",
      "loss: 0.170809  [  960/ 1020]\n",
      "loss: 0.111543  [ 1020/ 1020]\n",
      "Test Error: \n",
      " Accuracy: 36.8%, Avg loss: 2.671555 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.092677  [   64/ 1020]\n",
      "loss: 0.119602  [  128/ 1020]\n",
      "loss: 0.072120  [  192/ 1020]\n",
      "loss: 0.066074  [  256/ 1020]\n",
      "loss: 0.105184  [  320/ 1020]\n",
      "loss: 0.136171  [  384/ 1020]\n",
      "loss: 0.080117  [  448/ 1020]\n",
      "loss: 0.150493  [  512/ 1020]\n",
      "loss: 0.054983  [  576/ 1020]\n",
      "loss: 0.070635  [  640/ 1020]\n",
      "loss: 0.072167  [  704/ 1020]\n",
      "loss: 0.137168  [  768/ 1020]\n",
      "loss: 0.085974  [  832/ 1020]\n",
      "loss: 0.073039  [  896/ 1020]\n",
      "loss: 0.061349  [  960/ 1020]\n",
      "loss: 0.118470  [ 1020/ 1020]\n",
      "Test Error: \n",
      " Accuracy: 37.2%, Avg loss: 2.702543 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.053637  [   64/ 1020]\n",
      "loss: 0.092386  [  128/ 1020]\n",
      "loss: 0.076480  [  192/ 1020]\n",
      "loss: 0.061193  [  256/ 1020]\n",
      "loss: 0.077343  [  320/ 1020]\n",
      "loss: 0.063815  [  384/ 1020]\n",
      "loss: 0.064301  [  448/ 1020]\n",
      "loss: 0.062555  [  512/ 1020]\n",
      "loss: 0.070819  [  576/ 1020]\n",
      "loss: 0.080619  [  640/ 1020]\n",
      "loss: 0.066943  [  704/ 1020]\n",
      "loss: 0.040997  [  768/ 1020]\n",
      "loss: 0.077888  [  832/ 1020]\n",
      "loss: 0.046665  [  896/ 1020]\n",
      "loss: 0.089714  [  960/ 1020]\n",
      "loss: 0.059391  [ 1020/ 1020]\n",
      "Test Error: \n",
      " Accuracy: 37.5%, Avg loss: 2.647720 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.059420  [   64/ 1020]\n",
      "loss: 0.050367  [  128/ 1020]\n",
      "loss: 0.042608  [  192/ 1020]\n",
      "loss: 0.054889  [  256/ 1020]\n",
      "loss: 0.034525  [  320/ 1020]\n",
      "loss: 0.031878  [  384/ 1020]\n",
      "loss: 0.040076  [  448/ 1020]\n",
      "loss: 0.048691  [  512/ 1020]\n",
      "loss: 0.055790  [  576/ 1020]\n",
      "loss: 0.053206  [  640/ 1020]\n",
      "loss: 0.081816  [  704/ 1020]\n",
      "loss: 0.040250  [  768/ 1020]\n",
      "loss: 0.045261  [  832/ 1020]\n",
      "loss: 0.042800  [  896/ 1020]\n",
      "loss: 0.033913  [  960/ 1020]\n",
      "loss: 0.038383  [ 1020/ 1020]\n",
      "Test Error: \n",
      " Accuracy: 39.9%, Avg loss: 2.561432 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.044190  [   64/ 1020]\n",
      "loss: 0.036678  [  128/ 1020]\n",
      "loss: 0.025598  [  192/ 1020]\n",
      "loss: 0.033990  [  256/ 1020]\n",
      "loss: 0.030534  [  320/ 1020]\n",
      "loss: 0.058792  [  384/ 1020]\n",
      "loss: 0.061728  [  448/ 1020]\n",
      "loss: 0.033832  [  512/ 1020]\n",
      "loss: 0.033826  [  576/ 1020]\n",
      "loss: 0.035333  [  640/ 1020]\n",
      "loss: 0.031297  [  704/ 1020]\n",
      "loss: 0.037814  [  768/ 1020]\n",
      "loss: 0.022711  [  832/ 1020]\n",
      "loss: 0.094213  [  896/ 1020]\n",
      "loss: 0.027309  [  960/ 1020]\n",
      "loss: 0.033467  [ 1020/ 1020]\n",
      "Test Error: \n",
      " Accuracy: 38.4%, Avg loss: 2.623161 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.022568  [   64/ 1020]\n",
      "loss: 0.036959  [  128/ 1020]\n",
      "loss: 0.029067  [  192/ 1020]\n",
      "loss: 0.025699  [  256/ 1020]\n",
      "loss: 0.061210  [  320/ 1020]\n",
      "loss: 0.049559  [  384/ 1020]\n",
      "loss: 0.080787  [  448/ 1020]\n",
      "loss: 0.028370  [  512/ 1020]\n",
      "loss: 0.020356  [  576/ 1020]\n",
      "loss: 0.033941  [  640/ 1020]\n",
      "loss: 0.036748  [  704/ 1020]\n",
      "loss: 0.037953  [  768/ 1020]\n",
      "loss: 0.057575  [  832/ 1020]\n",
      "loss: 0.048866  [  896/ 1020]\n",
      "loss: 0.034704  [  960/ 1020]\n",
      "loss: 0.039715  [ 1020/ 1020]\n",
      "Test Error: \n",
      " Accuracy: 36.9%, Avg loss: 2.700257 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.040159  [   64/ 1020]\n",
      "loss: 0.038755  [  128/ 1020]\n",
      "loss: 0.029065  [  192/ 1020]\n",
      "loss: 0.042667  [  256/ 1020]\n",
      "loss: 0.024820  [  320/ 1020]\n",
      "loss: 0.058205  [  384/ 1020]\n",
      "loss: 0.040304  [  448/ 1020]\n",
      "loss: 0.028937  [  512/ 1020]\n",
      "loss: 0.025290  [  576/ 1020]\n",
      "loss: 0.020773  [  640/ 1020]\n",
      "loss: 0.041823  [  704/ 1020]\n",
      "loss: 0.026327  [  768/ 1020]\n",
      "loss: 0.024990  [  832/ 1020]\n",
      "loss: 0.028743  [  896/ 1020]\n",
      "loss: 0.026822  [  960/ 1020]\n",
      "loss: 0.032633  [ 1020/ 1020]\n",
      "Test Error: \n",
      " Accuracy: 38.3%, Avg loss: 2.622852 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.022537  [   64/ 1020]\n",
      "loss: 0.023250  [  128/ 1020]\n",
      "loss: 0.033122  [  192/ 1020]\n",
      "loss: 0.047930  [  256/ 1020]\n",
      "loss: 0.033282  [  320/ 1020]\n",
      "loss: 0.018233  [  384/ 1020]\n",
      "loss: 0.018140  [  448/ 1020]\n",
      "loss: 0.049165  [  512/ 1020]\n",
      "loss: 0.019314  [  576/ 1020]\n",
      "loss: 0.039784  [  640/ 1020]\n",
      "loss: 0.022958  [  704/ 1020]\n",
      "loss: 0.046333  [  768/ 1020]\n",
      "loss: 0.035658  [  832/ 1020]\n",
      "loss: 0.031111  [  896/ 1020]\n",
      "loss: 0.036254  [  960/ 1020]\n",
      "loss: 0.023555  [ 1020/ 1020]\n",
      "Test Error: \n",
      " Accuracy: 37.5%, Avg loss: 2.685737 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.022670  [   64/ 1020]\n",
      "loss: 0.024657  [  128/ 1020]\n",
      "loss: 0.038552  [  192/ 1020]\n",
      "loss: 0.037791  [  256/ 1020]\n",
      "loss: 0.029482  [  320/ 1020]\n",
      "loss: 0.035941  [  384/ 1020]\n",
      "loss: 0.019173  [  448/ 1020]\n",
      "loss: 0.036715  [  512/ 1020]\n",
      "loss: 0.021686  [  576/ 1020]\n",
      "loss: 0.018970  [  640/ 1020]\n",
      "loss: 0.031146  [  704/ 1020]\n",
      "loss: 0.039784  [  768/ 1020]\n",
      "loss: 0.022563  [  832/ 1020]\n",
      "loss: 0.020167  [  896/ 1020]\n",
      "loss: 0.236958  [  960/ 1020]\n",
      "loss: 0.040288  [ 1020/ 1020]\n",
      "Test Error: \n",
      " Accuracy: 38.0%, Avg loss: 2.634284 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.018987  [   64/ 1020]\n",
      "loss: 0.024416  [  128/ 1020]\n",
      "loss: 0.017921  [  192/ 1020]\n",
      "loss: 0.020302  [  256/ 1020]\n",
      "loss: 0.039505  [  320/ 1020]\n",
      "loss: 0.090690  [  384/ 1020]\n",
      "loss: 0.023425  [  448/ 1020]\n",
      "loss: 0.023304  [  512/ 1020]\n",
      "loss: 0.037512  [  576/ 1020]\n",
      "loss: 0.018499  [  640/ 1020]\n",
      "loss: 0.023548  [  704/ 1020]\n",
      "loss: 0.057146  [  768/ 1020]\n",
      "loss: 0.029687  [  832/ 1020]\n",
      "loss: 0.037073  [  896/ 1020]\n",
      "loss: 0.044308  [  960/ 1020]\n",
      "loss: 0.024815  [ 1020/ 1020]\n",
      "Test Error: \n",
      " Accuracy: 37.4%, Avg loss: 2.701044 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.024762  [   64/ 1020]\n",
      "loss: 0.022673  [  128/ 1020]\n",
      "loss: 0.058065  [  192/ 1020]\n",
      "loss: 0.018454  [  256/ 1020]\n",
      "loss: 0.029986  [  320/ 1020]\n",
      "loss: 0.031573  [  384/ 1020]\n",
      "loss: 0.015366  [  448/ 1020]\n",
      "loss: 0.014730  [  512/ 1020]\n",
      "loss: 0.020100  [  576/ 1020]\n",
      "loss: 0.017122  [  640/ 1020]\n",
      "loss: 0.020852  [  704/ 1020]\n",
      "loss: 0.017913  [  768/ 1020]\n",
      "loss: 0.030417  [  832/ 1020]\n",
      "loss: 0.016588  [  896/ 1020]\n",
      "loss: 0.016880  [  960/ 1020]\n",
      "loss: 0.014992  [ 1020/ 1020]\n",
      "Test Error: \n",
      " Accuracy: 38.2%, Avg loss: 2.632414 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.018486  [   64/ 1020]\n",
      "loss: 0.013897  [  128/ 1020]\n",
      "loss: 0.020818  [  192/ 1020]\n",
      "loss: 0.024253  [  256/ 1020]\n",
      "loss: 0.017486  [  320/ 1020]\n",
      "loss: 0.013336  [  384/ 1020]\n",
      "loss: 0.011874  [  448/ 1020]\n",
      "loss: 0.015968  [  512/ 1020]\n",
      "loss: 0.019250  [  576/ 1020]\n",
      "loss: 0.018536  [  640/ 1020]\n",
      "loss: 0.011247  [  704/ 1020]\n",
      "loss: 0.033622  [  768/ 1020]\n",
      "loss: 0.017554  [  832/ 1020]\n",
      "loss: 0.012760  [  896/ 1020]\n",
      "loss: 0.014598  [  960/ 1020]\n",
      "loss: 0.019359  [ 1020/ 1020]\n",
      "Test Error: \n",
      " Accuracy: 38.8%, Avg loss: 2.606069 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.013468  [   64/ 1020]\n",
      "loss: 0.019568  [  128/ 1020]\n",
      "loss: 0.019449  [  192/ 1020]\n",
      "loss: 0.012896  [  256/ 1020]\n",
      "loss: 0.018942  [  320/ 1020]\n",
      "loss: 0.016405  [  384/ 1020]\n",
      "loss: 0.018880  [  448/ 1020]\n",
      "loss: 0.014547  [  512/ 1020]\n",
      "loss: 0.029615  [  576/ 1020]\n",
      "loss: 0.020332  [  640/ 1020]\n",
      "loss: 0.009602  [  704/ 1020]\n",
      "loss: 0.016627  [  768/ 1020]\n",
      "loss: 0.018285  [  832/ 1020]\n",
      "loss: 0.014170  [  896/ 1020]\n",
      "loss: 0.015607  [  960/ 1020]\n",
      "loss: 0.015730  [ 1020/ 1020]\n",
      "Test Error: \n",
      " Accuracy: 39.0%, Avg loss: 2.599161 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.013130  [   64/ 1020]\n",
      "loss: 0.023672  [  128/ 1020]\n",
      "loss: 0.015372  [  192/ 1020]\n",
      "loss: 0.016021  [  256/ 1020]\n",
      "loss: 0.013212  [  320/ 1020]\n",
      "loss: 0.013899  [  384/ 1020]\n",
      "loss: 0.016427  [  448/ 1020]\n",
      "loss: 0.011390  [  512/ 1020]\n",
      "loss: 0.020080  [  576/ 1020]\n",
      "loss: 0.014208  [  640/ 1020]\n",
      "loss: 0.015244  [  704/ 1020]\n",
      "loss: 0.016392  [  768/ 1020]\n",
      "loss: 0.013989  [  832/ 1020]\n",
      "loss: 0.011051  [  896/ 1020]\n",
      "loss: 0.010982  [  960/ 1020]\n",
      "loss: 0.015319  [ 1020/ 1020]\n",
      "Test Error: \n",
      " Accuracy: 39.4%, Avg loss: 2.588311 \n",
      "\n",
      "Early stopping triggered.\n",
      "Done! This took 72.357 minutes\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define early stopping parameters\n",
    "patience = 10\n",
    "min_delta = 0.001\n",
    "\n",
    "best_loss = float('inf')\n",
    "counter = 0\n",
    "\n",
    "# Timer\n",
    "start_time = time.time()\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    validation_loss = test_loop(test_dataloader, model, loss_fn)\n",
    "    scheduler.step(validation_loss)\n",
    "\n",
    "    # Early stopping logic\n",
    "    if validation_loss < best_loss - min_delta:\n",
    "        best_loss = validation_loss\n",
    "        counter = 0\n",
    "    else:\n",
    "        counter += 1\n",
    "        if counter >= patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "            \n",
    "end_time = round((time.time()-start_time)/60, 3)\n",
    "\n",
    "print(\"Done! This took\", end_time, \"minutes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V28",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
